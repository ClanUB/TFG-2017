from sklearn.base import BaseEstimator
from operator import itemgetter
from sklearn.metrics import mean_absolute_error
from scipy.stats import pearsonr
import pandas as pd
import numpy as np
import os
import statistics
import json

from utilFunctions import score2ranking

class RecUserBased(BaseEstimator):
    def __init__(self, name="User Based", kn=5, filename="", alpha=2, accMargin=2):
        self.name = name
        self.kn = kn
        self.filename = filename
        self.load_knn = os.path.exists(self.filename)
        
        self.alpha = alpha
        self.accMargin = accMargin
        
    
    def __str__(self):
        s = "name: "+self.name + "\tk neighbours: "+str(self.kn) + "\talpha: "+str(self.alpha) + "\taccMargin: "+str(self.accMargin)
        return s
        
        
    def fit(self, X_train, y_train, X_test):
        self.X_train = X_train
        self.y_train = y_train
        self.multi_samples = type(self.X_test) == type(pd.DataFrame())
        
        if self.load_knn:
            self.dict_knn = self.read_knn()
            
        else:
            self.dict_knn = {}
            if self.multi_samples:
                for i in range(len(self.X_test)):
                    student = self.X_test.iloc[i]
                    list_knn = self.KNN(student)
                    
                    studentId = student.name
                    self.dict_knn[studentId] = list_knn
            
            else:
                self.dict_knn[student.name] = self.KNN(student)
                
    
    def KNN(self, student):
        neighbours = {}
        n = len(self.X_train)
         
        for i in range(n):
            stuCompare = self.X_train.iloc[i]

            df_concat = pd.concat([student, stuCompare], axis=1)
            df_concat.dropna(how="any", inplace=True)
            
            if (len(df_concat)>=5):
                s1 = df_concat[df_concat.columns[0]]
                s2 = df_concat[df_concat.columns[1]]
                
                p = pearsonr(s1, s2)[0]
                if (not np.isnan(p)):
                    neighbours[i] = round(float(p), 4)
        
        if (len(neighbours)<self.kn):
            kn = len(neighbours)
        else:
            kn = self.kn
        list_knn = sorted(neighbours.items(), key=itemgetter(1), reverse = True)[:kn]
        return list_knn    
    
    
    def recommend(self, student):
        y_subjects = self.y_train.columns #class labels
        prediction = pd.Series([0.0]*len(y_subjects), index=y_subjects) #Inicializacion del resultado
        
        for subject in y_subjects:
            sum_p = 0
            sum_weighing = 0
            list_knn = self.dict_knn[student.name]
            
            for i, p in list_knn:
                sim_stu_y = self.y_train.iloc[i]
                sum_p += p
                sum_weighing += p*sim_stu_y[subject]
            
            rank_score = sum_weighing / sum_p
            prediction[subject] = rank_score
        
        return prediction
    
    
    #===========================================================================
    # Predecir el ranking de las asignaturas para varios alumnos o un solo alumno
    # X_test: DataFrame(varios alumnos) or Series(un solo alumno) 
    # 
    # df_pred: resultado de predicciones tipo DataFrame or
    # pred: resultado de prediccion unitaria tipo Series
    #===========================================================================
    def predict(self):
        if self.multi_samples:
            predictions = []
            
            for studentId in self.X_test.index:
                student = self.X_test.loc[studentId]
                pred = self.recommend(student) #Predecir via recomendacion
                
                predictions.append(pred)
            
            df_pred = pd.DataFrame(predictions, index=self.X_test.index)
            df_pred_r = score2ranking(df_pred, reverse=False)
            return df_pred_r 
        
        else:
            pred = self.recommend(self.X_test)
            df_pred = pd.DataFrame(pred, index=self.X_test.index)
            df_pred_r = score2ranking(df_pred, reverse=False)
            return df_pred_r
        

    def score(self, y_test):
        y_pred = self.predict()
        df_error = abs(y_pred-y_test)
        error = df_error.sum().sum() / float(len(df_error))
        return error
    
    
    def write_knn(self):
        dict = {str(k): v for k,v in self.dict_knn.items()}
        fout = open(self.filename, "w")
        fout.write(json.dumps(dict))
        
        
    def read_knn(self):
        fin = open(self.filename, "r")
        text = fin.read()
        dict = eval(text)
        dict = {int(k): v for k,v in dict.items()}
        return dict
    #===========================================================================
    # #===========================================================================
    # # Hacer la estimacion del ranking de las diez asignaturas del segundo anio del alumno que se testea
    # # student: Series, el alumno a testear
    # # 
    # # prediction: Series, el resultado de estimacion
    # #===========================================================================
    # def recommend(self, student):
    #     y_subjects = self.y_train.columns #class labels
    #     list_knn = self.KNN(student)
    #     list_accs = self.getListAccs(student, list_knn)
    #     
    #     prediction = pd.Series([0]*len(y_subjects), index=y_subjects) #Inicializacion del resultado
    #     median_list = []
    #     
    #     for subject in y_subjects:
    #         weighted_ranks = []
    #         #Estimar la puntuacion del ranking de la asignatura ponderando los k vecinos mas cercanos
    #         for i, acc_score in list_accs:
    #             sim_stu_y = self.y_train.iloc[i]
    #             rank = sim_stu_y[subject]
    #             if (acc_score==0): #Evitar que la lista de weighted_ranks sea vacia
    #                 acc_score = 1
    #             weighted_ranks += [rank]*acc_score #Ponderar el ranking
    #         
    #         median = statistics.median(weighted_ranks)
    #         median_list.append((subject, median))
    #         
    #     rank_list = range(1, len(y_subjects)+1)
    #     sorted_medians = sorted(median_list, key=itemgetter(1), reverse=False)
    #     
    #     for i in range(len(y_subjects)): #Determinar el ranking segun el valor de la mediana obtenida de cada asignatura.
    #         subject = sorted_medians[i][0]
    #         rank = rank_list[i]
    #         prediction[subject] = rank
    #     
    #     return prediction
    #===========================================================================
    
    
    #===============================================================================
    #     #===========================================================================
    #     # Obtener los k vecinos con mayor puntuacion de similitud, haciendo recorrido en la muestra entrenada.
    #     # student: Series, el alumno a testear
    #     # 
    #     # list_accs: List, lista de k vecinos con mayor puntuacion de similitud
    #     #===========================================================================
    #     def KNN(self, student):
    #         neighbours = {}
    #         n = len(self.X_train)
    #          
    #         for i in range(n):
    #             stuCompare = self.X_train.iloc[i]
    # 
    #             mae = mean_absolute_error(student, stuCompare) #Medida de similitud, 0.0 es la mejor puntuacion
    #             neighbours[i] = mae
    #                 
    #         list_knn = sorted(neighbours.items(), key=itemgetter(1), reverse = False)[:self.kn]
    #         list_knn =[x[0] for x in list_knn]
    #         return list_knn
    #===============================================================================

    #===========================================================================
    # #===========================================================================
    # # Calcular la certeza de dos vectores, si la diferencia esta dentro del margen, es un acierto
    # # v1: array-like
    # # v2: array-like
    # # 
    # # acc: int, puntuacion de certeza
    # #===========================================================================
    # def acc_score_margin(self, v1, v2):
    #     diff = abs(v1 - v2)
    #     acc = (diff<=self.accMargin).sum()
    #     
    #     return acc
    #===========================================================================
    
    
    #===========================================================================
    # def getListAccs(self, student, list_knn):
    #     list_accs = []
    #     for j in range(self.kn):
    #         knn_j = self.X_train.iloc[list_knn[j]]
    #         acc = self.acc_score_margin(student, knn_j)
    #         
    #         acc_tuple = (list_knn[j], acc)
    #         list_accs.append(acc_tuple)
    #         
    #     return list_accs
    #===========================================================================
        