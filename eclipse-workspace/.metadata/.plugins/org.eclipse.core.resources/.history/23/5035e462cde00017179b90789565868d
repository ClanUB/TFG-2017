from loadData import loadData
from randomForest import rf_qual_prediction, rf_rank_prediction
from binClassifier import bc_qual_prediction, bc_binary_prediction
from RecUserBased import RecUserBased
import utilFunctions

import pandas as pd
import numpy as np
from time import time
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from statistics import mean

n_splits = 10
random_state = 0
kn = 5
dict_idEns = {"mates": "G1042", "info": "G1077", "low": ""}

#===============================================================================
# Lanza el menu que muestra opciones de computacion con el Random Forest
# X: DataFrame, data
# y: DataFrame, target
#===============================================================================
def RF_menuOptions(X, y):
    exit = False
    
    while(not exit):
        option = input("Selecciona una opcion:\n1. Ranking mediante prediccion de notas\n2. Prediccion de ranking\n\
3. Aprobado/suspenso mediante prediccion de notas\n4. Clasificacion binaria de aprobado/suspenso\n")
        
        if option=="1":
            rf_qual_prediction(X, y)
            
        elif option=="2":
            rf_rank_prediction(X, y)
            
        elif option=="3":
            bc_qual_prediction(X, y)
            
        elif option=="4":
            bc_binary_prediction(X, y)
            
        elif option=="5":
            exit = True
            
        else:
            print("opcion erronea.")

def rec_submenuOption1(X, y):
    leave = False
    
    while(not leave):
        print("PREDICCION MEDIANTE RANKING")
        option = input("Selecciona una opcion:\n1. Eliminacion de los MV\n2. Reemplazo de los MV\n")
        
        if option=="1":
            print("Elimination case:")
            df_concat = pd.concat([X, y], axis=1)
            df_concat.dropna(axis=0, how="any", inplace=True)
            X_copy = np.round(df_concat.iloc[:, :10], decimals=2)
            y_copy = np.round(df_concat.iloc[:, 10:20], decimals=2)
                 
            #Ranking conversion
            X_copy = utilFunctions.score2ranking(X_copy)
            y_copy = utilFunctions.score2ranking(y_copy)
            rec = RecUserBased(kn=kn) #Recomendador basado en usuarios
             
            kf = KFold(n_splits=n_splits, random_state=random_state)
            cross_validation(rec, X_copy, y_copy, kf) 
            
        elif option=="2":
            print("Replacement case:")
            X_copy, y_copy = X.copy(), y.copy() #Hacer la copia, porque la siguiente instruccion modifica el contenido 
            
            utilFunctions.fill_mv(X_copy)
            X_copy = np.round(X_copy, decimals=2)
                  
            utilFunctions.fill_mv(y_copy)
            y_copy = np.round(y_copy, decimals=2)
             
            #Ranking conversion
            X_copy = utilFunctions.score2ranking(X_copy)
            y_copy = utilFunctions.score2ranking(y_copy)
            rec = RecUserBased(kn=kn) #Recomendador basado en usuarios
              
            kf = KFold(n_splits=n_splits, random_state=random_state)
            cross_validation(rec, X_copy, y_copy, kf)
            
        elif option=="3":
            leave = True
            
        else:
            print("opcion erronea.")

def rec_submenuOption2(X, y):
    leave = False
    
    while(not leave):
        print("PREDICCION MEDIANTE CALIFICACIONES")
        option = input("Selecciona una opcion:\n1. Eliminacion de los MV\n2. Reemplazo de los MV\n3. Mantener los MV\n")
        
        if option=="1":
            print("Elimination case:")
            df_concat = pd.concat([X, y], axis=1)
            df_concat.dropna(axis=0, how="any", inplace=True)
            X_copy = np.round(df_concat.iloc[:, :10], decimals=2)
            y_copy = np.round(df_concat.iloc[:, 10:20], decimals=2)
                 
            rec = RecUserBased(kn=kn, reverse=True) #Recomendador basado en usuarios
            kf = KFold(n_splits=n_splits, random_state=random_state)
            cross_validation(rec, X_copy, y_copy, kf, True) 
            
        elif option=="2":
            print("Replacement case:")
            X_copy, y_copy = X.copy(), y.copy() #Hacer la copia, porque la siguiente instruccion modifica el contenido 
            
            utilFunctions.fill_mv(X_copy)
            X_copy = np.round(X_copy, decimals=2)
                  
            utilFunctions.fill_mv(y_copy)
            y_copy = np.round(y_copy, decimals=2)
             
            rec = RecUserBased(kn=kn, reverse=True) #Recomendador basado en usuarios
            kf = KFold(n_splits=n_splits, random_state=random_state)
            cross_validation(rec, X_copy, y_copy, kf, True)
           
        elif option=="3":
            print("Keeping case")
            rec = RecUserBased(kn=kn, reverse=True) #Recomendador basado en usuarios
              
            kf = KFold(n_splits=n_splits, random_state=random_state)
            cross_validation(rec, X, y, kf, True, True)
            
        elif option=="4":
            leave = True
            
        else:
            print("opcion erronea.")
            
def rec_menuOptions(X, y):
    leave = False
    
    while(not leave):
        print("RECOMENDADOR BASADO EN USUARIOS")
        option = input("Selecciona una opcion:\n1. Prediccion mediante ranking\n2. Prediccion mediante calificaciones\n")
        
        if option=="1":
            rec_submenuOption1(X, y)
            
        elif option=="2":
            rec_submenuOption2(X, y)
            
        elif option=="3":
            leave = True
            
        else:
            print("opcion erronea.")
            
#===============================================================================
# Calculo de la puntuancion de cross validation
# clf: BaseEstimator, el clasificador
# X: DataFrame, data
# y: DataFrame, target
# kf: Kfold, iterador de cross validation
#===============================================================================
def cross_validation(clf, X, y, kf, qual=False, keepMv=False):
    yPair_list = []
    splits = kf.split(X)
    
    for i, index in enumerate(splits):
        print("Fold", i)
        
        train_index = index[0]
        test_index = index[1]
    
        clf.fit(X.iloc[train_index], y.iloc[train_index])
        
        X_test = X.iloc[test_index]
        
        t0 = time()
        y_pred = clf.predict(X_test)
        t_used = time()-t0
        print("time used for the prediction is:", t_used)
        
        y_test = y.iloc[test_index]  
        
        if qual and not keepMv:
            y_test = utilFunctions.score2ranking(y_test)
            
        yPair_list.append((y_pred, y_test))
    
    list_mae, list_acc, list_accMargin = [], [], []
    if keepMv:
        for yp, yt in yPair_list:
            error, n_match_acc, n_match_accM = 0, 0, 0
            length = 0
            for i in range(len(yp)):
                row_yp = yp.iloc[i]
                row_yt = yt.iloc[i]
                
                df_concat = pd.concat([row_yp, row_yt], axis=1)
                df_concat.dropna(how="any", inplace=True)
                
                s1 = df_concat.T.iloc[0]
                s2 = df_concat.T.iloc[1]
                
                s1 = utilFunctions.score2ranking(s1, False)
                s2 = utilFunctions.score2ranking(s2)
            
                error += utilFunctions.compute_mae(s1, s2)
                n_match_acc += utilFunctions.compute_accuracy(s1, s2)
                n_match_accM += utilFunctions.compute_accMargin(s1, s2)
                
                length += len(s1)
                
            mae = error / float(length)
            accuracy = n_match_acc / float(length)
            accMargin = n_match_accM /float(length)
            
            list_mae.append(mae)
            list_acc.append(accuracy)
            list_accMargin.append(accMargin)
                
    else:
        for yp, yt in yPair_list:
            mae = utilFunctions.compute_mae(yp, yt)
            accuracy = utilFunctions.compute_accuracy(yp, yt)
            accMargin = utilFunctions.compute_accMargin(yp, yt)
            list_mae.append(mae)
            list_acc.append(accuracy)
            list_accMargin.append(accMargin)
        
    print("Cross validation:", \
          "\nmae is: ", mean(list_mae), \
          "\naccuracy is: ", mean(list_acc), \
          "\naccMargin is: ", mean(list_accMargin))
    

#===============================================================================
# Evaluacion de prediccion del clasificador, test unitario
# clf: BaseEstimator, el clasificador
# X: DataFrame, data
# y: DataFrame, target
#===============================================================================
def single_validation(clf, X, y):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=33)
    
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    
    df_error = abs(y_pred-y_test)
    error = df_error.sum().sum() / float(df_error.shape[0]*df_error.shape[1])
    print ("error=",error)
    
    return y_pred


#===============================================================================
# Funcion principal que prepara todos los datos necesarios, y llama a las demas funciones para ejecutar 
# diferentes funcionalidades implementadas.
#===============================================================================
def main():
    id_ens = dict_idEns["info"]
    X, y = loadData(id_ens) #df_year1, df_year2
    rec_menuOptions(X, y)
    
    print("final")

    
main()